{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4 and Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "\n",
    "openai.api_key = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = \"\"\"\n",
    "def remove_common_prefix(x, prefix, ws_prefix):\n",
    "    x[\"completion\"] = x[\"completion\"].str[len(prefix):]\n",
    "    if ws_prefix:\n",
    "        # keep the single whitespace as prefix\n",
    "        x[\"completion\"] = \" \" + x[\"completion\"]\n",
    "    \n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"you are a Python explaining assistant\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Explain the following function: {func}\"}\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    messages=messages,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `remove_common_prefix` function takes three arguments: a pandas dataframe `x`, a string `prefix`, and a boolean value `ws_prefix`.\n",
      "\n",
      "The function removes the common prefix from the \"completion\" column of the input dataframe `x`. It achieves this by calling the `str` method of the column and passing it the length of the prefix as an argument, which causes the prefix to be removed.\n",
      "\n",
      "If the value of `ws_prefix` is True, then a single whitespace is added back as a prefix to the \"completion\" column.\n",
      "\n",
      "Finally, the function returns the modified `x` dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(res[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking GPT-4 to Calculate Time Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_sort = \"\"\"\n",
    "def sort(array):\n",
    "    for i in range(len(array)):\n",
    "        for j in range(0, len(array) - i -1):\n",
    "            temp = array[j]\n",
    "            array[j] = array[j+1]\n",
    "            array[j+1] = temp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Calculate the time complexity of the following function: {bubble_sort}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7IGc8gG5bQOQOnpKX7sVFmwkUkR7D at 0x7fbdf8c5d4f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"The function implements the Bubble Sort algorithm. The time complexity of this algorithm is O(n^2), where n is the length of the array. \\n\\nThe outer loop runs n times, and for each iteration, the inner loop runs (n-1), (n-2), (n-3), ..., 1 times. Therefore, the total number of iterations is: \\n\\n(n-1) + (n-2) + (n-3) + ... + 1 \\n\\nThis sum can be simplified to: \\n\\nn(n-1)/2 \\n\\nwhich is O(n^2). \\n\\nSo, the time complexity of the function is O(n^2).\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1684588124,\n",
       "  \"id\": \"chatcmpl-7IGc8gG5bQOQOnpKX7sVFmwkUkR7D\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 135,\n",
       "    \"prompt_tokens\": 71,\n",
       "    \"total_tokens\": 206\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.ChatCompletion.create(\n",
    "    messages=messages,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Javascript to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = \"\"\"\n",
    "function myster(arr) {\n",
    "    return arr.reduce(function (p, v)) {\n",
    "        return (p < v ? p : v);\n",
    "    });\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Translate the following JaveScript to Python: {js}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def myster(arr):\n",
      "    return reduce(lambda p, v: p if p < v else v, arr)\n"
     ]
    }
   ],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    messages=messages,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "print(res[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking GPT to Find Bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"rol\"\n",
    "    \n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
