{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.6-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from openai) (3.7.4)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from openai) (2.24.0)\n",
      "Requirement already satisfied: tqdm in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from openai) (4.50.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (4.4.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (3.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (20.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.5.1)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (5.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2022.9.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/morgan/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2.10)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7ERhA3xwrFnI8z2PS8TulTjjEVpie at 0x7f8ae003c9f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n1. Tokyo, Japan\\n2. Delhi, India\\n3. Shanghai, China\\n4. Sao Paulo, Brazil\\n5. Mexico City, Mexico\\n6. Cairo, Egypt\\n7. Mumbai, India\\n8. Beijing, China\\n9. Dhaka, Bangladesh\\n10. Osaka, Japan\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683677408,\n",
       "  \"id\": \"cmpl-7ERhA3xwrFnI8z2PS8TulTjjEVpie\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 64,\n",
       "    \"prompt_tokens\": 9,\n",
       "    \"total_tokens\": 73\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"The top 10 most populate cities are: \",\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    prompt=\"Generate a list of the best movies of all time\",\n",
    "    model=\"text-davinci-003\",\n",
    "    max_tokens=200,\n",
    "    stop=\"5.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. The Godfather (1972)\n",
      "2. Pulp Fiction (1994)\n",
      "3. The Shawshank Redemption (1994)\n",
      "4. Schindler's List (1993)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7ERvUcEmvL3mFIIdl1Ou6c1qKvKQm at 0x7f8ae13e8cc0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"I went to the park and had lots of fun. I love to swing and run around.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683678296,\n",
       "  \"id\": \"cmpl-7ERvUcEmvL3mFIIdl1Ou6c1qKvKQm\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 19,\n",
       "    \"prompt_tokens\": 107,\n",
       "    \"total_tokens\": 126\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a chatbot that speaks like a toddler.\n",
    "User: Hi, how are you?\n",
    "Chatbot: I'm good.\n",
    "User: Tell me about your family.\n",
    "Chatbot: I have a mommy, daddy, baby sister and two kitties.\n",
    "User: What do you do for fun?\n",
    "Chatbot: I like to play with my friends, color, and watch cartoons. Guess what I did today?\n",
    "User: What did you do today?\n",
    "Chatbot: \n",
    "\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    model=\"text-davinci-003\",\n",
    "    max_tokens=200,\n",
    "    stop=[\"Chatbot:\", \"User:\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N and Echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7ES4Dka2xlNhuZxIgFCGCuYCu4lZb at 0x7f8ae13e8310> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nQ: Why did the Grim Reaper go to the doctor?\\nA: He needed a death certificate.\"\n",
       "    },\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 1,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nQ: What did one graveyard say to the other?\\nA: \\\"I'm dying to hear your jokes!\\\"\"\n",
       "    },\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 2,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nQ: Why did the skeleton go to the dentist? \\nA: He wanted to improve his skull-elligence!\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683678837,\n",
       "  \"id\": \"cmpl-7ES4Dka2xlNhuZxIgFCGCuYCu4lZb\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 74,\n",
       "    \"prompt_tokens\": 6,\n",
       "    \"total_tokens\": 80\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"tell me a joke about death\",\n",
    "    # max_tokens applies to each choice/text seperately\n",
    "    max_tokens=100,\n",
    "    n=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7ESBNoycn5wrGq9HwwmCfzuhf7JWL at 0x7f8ae13f2400> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"Q: What is the tallest building in the world?\\n\\nA: The Burj Khalifa in Dubai is the tallest building in the world, standing at 828 meters (2,717 feet).\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683679281,\n",
       "  \"id\": \"cmpl-7ESBNoycn5wrGq9HwwmCfzuhf7JWL\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 31,\n",
       "    \"prompt_tokens\": 11,\n",
       "    \"total_tokens\": 42\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# echo param\n",
    "\n",
    "openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Q: What is the tallest building in the world?\",\n",
    "    max_tokens=100,\n",
    "    echo=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Completion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7ESN2ZsXUTxM7PZvadKql5AIUY8Ec at 0x7f8ae13f4a40> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nI'm so sorry that you're feeling sad. Here are a few ideas to help you turn that frown upside down:\\n-Go for a walk in nature and get some fresh air.\\n-Listen to your favorite upbeat songs.\\n-Watch funny videos or movies.\\n-Call a friend and have a good laugh together.\\n-Write down 3 things you're thankful for.\\n-Try a new hobby or activity.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683680004,\n",
       "  \"id\": \"cmpl-7ESN2ZsXUTxM7PZvadKql5AIUY8Ec\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 89,\n",
       "    \"prompt_tokens\": 8,\n",
       "    \"total_tokens\": 97\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    prompt=\"I'm sad. Make me happy.\",\n",
    "    model=\"text-davinci-003\",\n",
    "    max_tokens=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Model Performance and Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7ESaXhbpCSXKfKVsSXffpAncJyU14 at 0x7f8ae1406540> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n-Tell me a joke!\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side!\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683680841,\n",
       "  \"id\": \"cmpl-7ESaXhbpCSXKfKVsSXffpAncJyU14\",\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 27,\n",
       "    \"prompt_tokens\": 8,\n",
       "    \"total_tokens\": 35\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# curie\n",
    "openai.Completion.create(\n",
    "    prompt=\"I'm sad. Make me happy.\",\n",
    "    model=\"text-curie-001\",\n",
    "    max_tokens=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
